{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9815e49f-7361-4cf6-a993-06c54b9005f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import biosppy.signals.ecg as ecg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbee5afa-eda9-40ea-85e8-38f6e21c06b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching preprocessed data\n"
     ]
    }
   ],
   "source": [
    "#import raw features\n",
    "raw_train_data = pd.read_csv('Data/train.csv', index_col='id')\n",
    "train_data_X = raw_train_data.drop(columns=['y']).to_numpy(dtype='float32')\n",
    "train_data_y = raw_train_data[['y']].to_numpy(dtype='float32').ravel()\n",
    "\n",
    "#import means vars medians\n",
    "raw_train_data_means = np.loadtxt(\"Data/train_means.csv\", delimiter=\",\")\n",
    "train_data_means = raw_train_data_means.astype(np.float32)\n",
    "\n",
    "raw_train_data_vars = np.loadtxt(\"Data/train_vars.csv\", delimiter=\",\")\n",
    "train_data_vars = raw_train_data_vars.astype(np.float32)\n",
    "\n",
    "raw_train_data_medians = np.loadtxt(\"Data/train_medians.csv\", delimiter=\",\")\n",
    "train_data_medians = raw_train_data_medians.astype(np.float32)\n",
    "\n",
    "def get_peaks(file_name):\n",
    "    peaks = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            arr = np.array(list(map(int, line.strip().split(','))))\n",
    "            peaks.append(arr)\n",
    "            \n",
    "    return peaks\n",
    "\n",
    "train_r_peaks = get_peaks(\"Data/train_peaks.csv\")\n",
    "test_r_peaks = get_peaks(\"Data/test_peaks.csv\")\n",
    "\n",
    "print(\"Finished fetching preprocessed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fad7a436-ae0a-4c67-9b48-34980ec02c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_derivative(signal):\n",
    "    return np.diff(signal)\n",
    "\n",
    "def get_mobility(signal, var):\n",
    "    return np.sqrt(np.var(get_derivative(signal)) / var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "4ebe988e-4221-43f6-b155-8fb63a31b79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_features(data_raw, data_peaks, data_means, data_vars, data_medians, idx):\n",
    "    \n",
    "    raw = data_raw[idx]\n",
    "    raw = raw[~np.isnan(raw)]\n",
    "    r_peaks = data_peaks[idx]\n",
    "    \n",
    "    # RAW Data ----------------------------------------------------------------------\n",
    "    \n",
    "    raw_mean = np.mean(raw)\n",
    "    raw_std = np.std(raw)\n",
    "    raw_median = np.median(raw)\n",
    "    raw_var = np.var(raw)\n",
    "    \n",
    "    raw_mav = np.mean(np.abs(raw))\n",
    "    raw_rms = np.sqrt(np.mean(raw**2))\n",
    "    raw_wl = np.sum(np.abs(get_derivative(raw))) / len(raw)\n",
    "    \n",
    "    raw_max = np.max(np.abs(raw))\n",
    "    raw_abssum = np.sum(np.abs(raw)) / len(raw)\n",
    "    raw_energy = np.sum(raw**2) /len(raw)\n",
    "    \n",
    "    raw_skeness = skew(raw)\n",
    "    raw_kurtosis = kurtosis(raw)\n",
    "    \n",
    "    raw_mobility = get_mobility(raw, raw_var)\n",
    "    raw_complexity = get_mobility(get_derivative(raw), np.var(get_derivative(raw))) / get_mobility(raw, raw_var)\n",
    "    \n",
    "    \n",
    "    f, Pxx = signal.welch(raw, 300, nperseg=1024)\n",
    "    spectral_centroid = np.sum(f * Pxx) / np.sum(Pxx)\n",
    "    \n",
    "    arith_mean = np.mean(Pxx)\n",
    "    geo_mean = np.exp(np.mean(np.log(Pxx)))  # Geometric mean (log-mean approach)\n",
    "    sfm = geo_mean / arith_mean\n",
    "    \n",
    "    roll_off_percentage = 0.85\n",
    "    total_energy = np.sum(Pxx)\n",
    "    cumulative_energy = np.cumsum(Pxx)\n",
    "    roll_off_index = np.where(cumulative_energy >= roll_off_percentage * total_energy)[0][0]\n",
    "    spectral_roll_off = f[roll_off_index]\n",
    "    \n",
    "    \n",
    "    # Averaged Data ----------------------------------------------------------------------\n",
    "    \n",
    "    mu = data_means[idx]\n",
    "    var = data_vars[idx]\n",
    "    md = data_medians[idx]\n",
    "    \n",
    "    if(len(r_peaks) == 1 and r_peaks[0] == -1):\n",
    "        r_nums = np.float64(0.0)\n",
    "        \n",
    "        mu_mav = np.float64(0.0)\n",
    "        mu_rms = np.float64(0.0)\n",
    "        mu_wl = np.float64(0.0)\n",
    "        \n",
    "        R_index = np.float64(0.0)\n",
    "        Q_index = np.float64(0.0)\n",
    "        S_index = np.float64(0.0)\n",
    "        P_index = np.float64(0.0)\n",
    "        T_index = np.float64(0.0)\n",
    "        \n",
    "        mu_max = np.float64(0.0)\n",
    "        mu_abssum = np.float64(0.0)\n",
    "        mu_energy = np.float64(0.0)\n",
    "    else:\n",
    "        r_nums = len(r_peaks) / (len(raw)*300)\n",
    "        \n",
    "        mu_mav = np.mean(np.abs(mu))\n",
    "        mu_rms = np.sqrt(np.mean(mu**2))\n",
    "        mu_wl = np.sum(np.abs(get_derivative(mu))) / 180\n",
    "        \n",
    "        R_index = np.argmax(mu)\n",
    "        \n",
    "        if R_index > 0:\n",
    "            reversed_slice = mu[:R_index][::-1]\n",
    "            min_index = np.argmin(reversed_slice)\n",
    "            Q_index = R_index - min_index - 1\n",
    "        else:\n",
    "            Q_index = np.float64(0.0)\n",
    "        \n",
    "        if R_index > 0:\n",
    "            slice = mu[:R_index]\n",
    "            min_index = np.argmin(slice)\n",
    "            S_index = R_index + min_index \n",
    "        else:\n",
    "            S_index = np.float64(0.0)\n",
    "            \n",
    "        if Q_index > 0:\n",
    "            reversed_slice = mu[:Q_index][::-1]\n",
    "            max_index = np.argmax(reversed_slice)\n",
    "            P_index = Q_index - max_index - 1\n",
    "        else:\n",
    "            P_index = np.float64(0.0)\n",
    "        \n",
    "        if S_index > 0:\n",
    "            slice = mu[:S_index]\n",
    "            max_index = np.argmin(slice)\n",
    "            T_index = S_index + max_index \n",
    "        else:\n",
    "            T_index = np.float64(0.0)\n",
    "        \n",
    "        mu_max = np.max(np.abs(mu))\n",
    "        mu_abssum = np.sum(np.abs(mu)) / len(mu)\n",
    "        mu_energy = np.sum(mu**2) /len(mu)\n",
    "\n",
    "    average_mean = np.mean(mu)\n",
    "    average_var = np.mean(var)\n",
    "    average_median = np.mean(md)\n",
    "    \n",
    "    if(len(r_peaks) <= 2):\n",
    "        skewness_mu = np.float64(0.0)\n",
    "        kurtosis_mu = np.float64(0.0)\n",
    "    else:\n",
    "        skewness_mu = skew(mu)\n",
    "        kurtosis_mu = kurtosis(mu)\n",
    "    \n",
    "    std_mean = np.std(mu)\n",
    "    std_var = np.std(var)\n",
    "    std_median = np.std(md)\n",
    "    \n",
    "    if(len(r_peaks) <= 2):\n",
    "        rr_intervals = np.float64(0.0)\n",
    "        sdnn = np.float64(0.0)\n",
    "        rmssd = np.float64(0.0)\n",
    "    else:\n",
    "        rr_intervals = np.diff(r_peaks) / 300\n",
    "        sdnn = np.std(rr_intervals)\n",
    "        rmssd = np.sqrt(np.mean(np.square(np.diff(rr_intervals))))\n",
    "    \n",
    "    feature_array = np.array([\n",
    "                        spectral_centroid, sfm, spectral_roll_off, r_nums,\n",
    "                        raw_mean, raw_std, raw_median, raw_skeness, raw_kurtosis, raw_var, raw_mobility, raw_complexity,\n",
    "                        raw_mav, raw_rms, raw_wl, raw_max, raw_abssum, raw_energy,\n",
    "                        R_index.astype(np.float32), Q_index.astype(np.float32), S_index.astype(np.float32),\n",
    "                        P_index.astype(np.float32), T_index.astype(np.float32),\n",
    "                        mu_mav, mu_rms, mu_wl, mu_max, mu_abssum, mu_energy,\n",
    "                        average_mean, average_var, average_median,\n",
    "                        skewness_mu, kurtosis_mu,\n",
    "                        std_mean, std_var, std_median,\n",
    "                        sdnn, rmssd\n",
    "                     ])\n",
    "    \n",
    "    return feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1040ef20-150e-4986-ac1e-1bd69205f1dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abba = get_features(train_data_X, train_r_peaks, train_data_means, train_data_vars, train_data_medians, 504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5aede020-e8c8-4c80-b235-cd27cb5b5cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 39)\n"
     ]
    }
   ],
   "source": [
    "stacked_arrays = []\n",
    "for i in range(5117):\n",
    "    abba = get_features(train_data_X, train_r_peaks, train_data_means, train_data_vars, train_data_medians, i)\n",
    "    stacked_arrays.append(abba)\n",
    "    \n",
    "features = np.vstack(stacked_arrays)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "849d08a5-cd71-4913-ae0c-146bd7b934f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.60148479e+00  2.68462161e-03  1.75781250e+01  5.81683159e-01\n",
      "  9.58626556e+01  1.10000000e+01 -5.76741604e-02  9.57839065e+00\n",
      "  9.18964941e+03  2.26179570e-01  1.95005846e+00  5.70144997e+01\n",
      "  9.58644180e+01  7.67397454e+00  5.55000000e+02  5.70144979e+01\n",
      "  9.18998656e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "float64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(features[4984])\n",
    "print(features.dtype)\n",
    "\n",
    "contains_nan = np.any(np.isnan(features))\n",
    "print(contains_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "a62c5f92-a5d5-4675-a5de-691fb0c92f42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 38)\n",
      "(5117,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(train_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b080030c-b306-4695-b40a-e692d5c72444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 40)\n",
      "[ 3.00000000e+00  8.09257722e+00  1.46454293e-02  1.52343750e+01\n",
      "  1.48111577e-05  1.93982964e+01  3.32239777e+02 -4.70000000e+01\n",
      "  1.10453693e+00  3.72997120e+00  1.10383266e+05  2.30824038e-01\n",
      "  2.78094506e+00  2.21401505e+02  3.32805603e+02  4.04160701e+01\n",
      "  1.71500000e+03  2.21401506e+02  1.10759560e+05  6.00000000e+01\n",
      "  2.00000000e+01  8.00000000e+01  5.00000000e+00  1.48000000e+02\n",
      "  9.82021179e+01  2.01381653e+02  2.25709147e+01  1.06473535e+03\n",
      "  9.82021159e+01  4.05545722e+04  7.19642181e+01  3.32658936e+02\n",
      "  3.10444450e+01  3.51544103e+00  1.33462243e+01  1.88084351e+02\n",
      "  8.15171509e+01  2.02075974e+02  4.57376290e-01  7.27783815e-01]\n"
     ]
    }
   ],
   "source": [
    "y_reshaped = train_data_y.reshape(-1, 1)\n",
    "result = np.hstack([y_reshaped, features])\n",
    "print(result.shape)\n",
    "print(result[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5998662b-a45d-46c5-bb1b-d39bbc545a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Data/features.csv\", result, delimiter=\",\", fmt=\"%.10f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "42c22ceb-92c8-4be2-a8db-7b4e59a4ffa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 39)\n",
      "[ 3.00000000e+00  8.09257698e+00  1.46454293e-02  1.52343750e+01\n",
      "  1.93982964e+01  3.32239777e+02 -4.70000000e+01  1.10453689e+00\n",
      "  3.72997117e+00  1.10383266e+05  2.30824038e-01  2.78094506e+00\n",
      "  2.21401505e+02  3.32805603e+02  4.04160690e+01  1.71500000e+03\n",
      "  2.21401505e+02  1.10759562e+05  6.00000000e+01  2.00000000e+01\n",
      "  8.00000000e+01  5.00000000e+00  1.48000000e+02  9.82021179e+01\n",
      "  2.01381653e+02  2.25709152e+01  1.06473535e+03  9.82021179e+01\n",
      "  4.05545703e+04  7.19642181e+01  3.32658936e+02  3.10444450e+01\n",
      "  3.51544094e+00  1.33462248e+01  1.88084351e+02  8.15171509e+01\n",
      "  2.02075974e+02  4.57376301e-01  7.27783799e-01]\n"
     ]
    }
   ],
   "source": [
    "gre = np.loadtxt(\"Data/features.csv\", delimiter=\",\")\n",
    "fe = gre.astype(np.float32)\n",
    "print(fe.shape)\n",
    "print(fe[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6a71c561-2b37-4d58-8e11-d484b88dcff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import raw features\n",
    "raw_train_data = pd.read_csv('Data/test.csv', index_col='id')\n",
    "test_data_X = raw_train_data.to_numpy(dtype='float32')\n",
    "\n",
    "#import means vars medians\n",
    "raw_test_data_means = np.loadtxt(\"Data/test_means.csv\", delimiter=\",\")\n",
    "test_data_means = raw_test_data_means.astype(np.float32)\n",
    "\n",
    "raw_test_data_vars = np.loadtxt(\"Data/test_vars.csv\", delimiter=\",\")\n",
    "test_data_vars = raw_test_data_vars.astype(np.float32)\n",
    "\n",
    "raw_test_data_medians = np.loadtxt(\"Data/test_medians.csv\", delimiter=\",\")\n",
    "test_data_medians = raw_test_data_medians.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5603d06a-606e-47b8-a434-102ef9e0f1df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5117, 39)\n"
     ]
    }
   ],
   "source": [
    "stacked = []\n",
    "for i in range(3411):\n",
    "    abba = get_features(test_data_X, test_r_peaks, test_data_means, test_data_vars, test_data_medians, i)\n",
    "    stacked.append(abba)\n",
    "    \n",
    "test_features = np.vstack(stacked)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9c204a77-099b-4848-a78a-b47a9139aa43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Data/test_features.csv\", test_features, delimiter=\",\", fmt=\"%.10f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd157417-8945-43f2-8a46-84adc4a37a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML Project 2 Env",
   "language": "python",
   "name": "aml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
